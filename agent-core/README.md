# OOMKilled Agent ğŸ¤–

Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ OOMKilled ì´ìŠˆë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ë¶„ì„í•˜ì—¬ í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” LangChain ê¸°ë°˜ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

- ğŸ” **ìë™ ê°ì§€**: OOMKilled ìƒíƒœì˜ íŒŒë“œë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ëƒ…ë‹ˆë‹¤
- ğŸ“Š **ìƒì„¸ ë¶„ì„**: íŒŒë“œì˜ ë¦¬ì†ŒìŠ¤ ì„¤ì •, ë¡œê·¸, ì´ë²¤íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤
- ğŸ’¡ **AI ê¶Œì¥ì‚¬í•­**: Gemini ë˜ëŠ” GPT-4ë¥¼ í™œìš©í•˜ì—¬ ì ì ˆí•œ ë©”ëª¨ë¦¬ ë¦¬ë¯¸íŠ¸ì™€ í•´ê²°ì±…ì„ ì œì‹œí•©ë‹ˆë‹¤
- ğŸ”§ **ìˆ˜ì • ê°€ì´ë“œ**: Deployment ìˆ˜ì • ë°©ë²•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤
- ğŸ”€ **ë‹¤ì¤‘ LLM ì§€ì›**: Google Geminiì™€ OpenAI GPTë¥¼ ì„ íƒí•´ì„œ ì‚¬ìš© ê°€ëŠ¥

## ì•„í‚¤í…ì²˜

```
agent-core/
â”œâ”€â”€ agents/           # LangChain ì—ì´ì „íŠ¸ ë¡œì§
â”œâ”€â”€ tools/            # K8s API í˜¸ì¶œ ë„êµ¬ë“¤
â”œâ”€â”€ prompts/          # LLM í”„ë¡¬í”„íŠ¸
â”œâ”€â”€ examples/         # ì‚¬ìš© ì˜ˆì œ
â”œâ”€â”€ config.py         # ì„¤ì •
â””â”€â”€ main.py          # CLI ì§„ì…ì 
```

## ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- Python 3.9+
- Kubernetes í´ëŸ¬ìŠ¤í„° ì ‘ê·¼ ê¶Œí•œ
- LLM API í‚¤:
  - **Gemini API í‚¤** (ê¶Œì¥, ë¬´ë£Œ): https://makersuite.google.com/app/apikey
  - ë˜ëŠ” **OpenAI API í‚¤**: https://platform.openai.com/api-keys

## ì„¤ì¹˜ ë° ì„¤ì •

### 1. ê°€ìƒí™˜ê²½ ìƒì„±

```bash
cd agent-core
python -m venv venv
source venv/bin/activate  # macOS/Linux
# ë˜ëŠ”
venv\Scripts\activate     # Windows
```

### 2. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

```bash
cp .env.example .env
```

`.env` íŒŒì¼ í¸ì§‘:

#### ì˜µì…˜ A: Gemini ì‚¬ìš© (ê¸°ë³¸ê°’, ê¶Œì¥)

```bash
LLM_PROVIDER=gemini
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-1.5-pro
KUBECONFIG=~/.kube/config
```

Gemini API í‚¤ëŠ” https://makersuite.google.com/app/apikey ì—ì„œ ë¬´ë£Œë¡œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ì˜µì…˜ B: OpenAI ì‚¬ìš©

```bash
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview
KUBECONFIG=~/.kube/config
```

### 4. Kubernetes ì ‘ê·¼ í™•ì¸

```bash
kubectl cluster-info
kubectl get pods -n default
```

## ì‚¬ìš© ë°©ë²•

### CLI ì‚¬ìš©

#### 1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  OOMKilled íŒŒë“œ ë¶„ì„ (Gemini ì‚¬ìš©)

```bash
python main.py -n default
```

#### 2. íŠ¹ì • íŒŒë“œ ë¶„ì„

```bash
python main.py -n default -p oom-test
```

#### 3. ìˆ˜ì • ë°©ë²• ê°€ì´ë“œ ë°›ê¸°

```bash
python main.py -n default -p oom-test --fix
```

#### 4. OpenAI ì‚¬ìš©í•˜ê¸°

```bash
python main.py -n default --provider openai
```

#### 5. ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©

```bash
# Gemini Pro 1.5 ì‚¬ìš©
python main.py -n default --provider gemini --model gemini-1.5-pro

# GPT-3.5 ì‚¬ìš©
python main.py -n default --provider openai --model gpt-3.5-turbo
```

### Python ì½”ë“œì—ì„œ ì‚¬ìš©

#### ê¸°ë³¸ ì‚¬ìš©ë²• (Gemini)

```python
from agents import OOMKilledAgent
from config import GEMINI_API_KEY

# Gemini ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
agent = OOMKilledAgent(
    api_key=GEMINI_API_KEY,
    model_name="gemini-1.5-pro",
    provider="gemini"
)

# ëª¨ë“  OOMKilled íŒŒë“œ ë¶„ì„
result = agent.analyze_oomkilled_pods(namespace="default")
print(result)

# íŠ¹ì • íŒŒë“œ ë¶„ì„
result = agent.analyze_specific_pod("oom-test", "default")
print(result)

# ìˆ˜ì • ë°©ë²• ê°€ì´ë“œ
result = agent.get_fix_instructions("oom-test", "default")
print(result)
```

#### OpenAI ì‚¬ìš©ë²•

```python
from agents import OOMKilledAgent
from config import OPENAI_API_KEY

# OpenAI ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
agent = OOMKilledAgent(
    api_key=OPENAI_API_KEY,
    model_name="gpt-4-turbo-preview",
    provider="openai"
)

# ì‚¬ìš©ë²•ì€ ìœ„ì™€ ë™ì¼
result = agent.analyze_specific_pod("oom-test", "default")
print(result)
```

#### ì»¤ìŠ¤í…€ ì¿¼ë¦¬

```python
from agents import OOMKilledAgent
from config import LLM_PROVIDER, GEMINI_API_KEY, OPENAI_API_KEY

# Providerì— ë”°ë¼ ì—ì´ì „íŠ¸ ìƒì„±
if LLM_PROVIDER == "gemini":
    agent = OOMKilledAgent(api_key=GEMINI_API_KEY, provider="gemini")
else:
    agent = OOMKilledAgent(api_key=OPENAI_API_KEY, provider="openai")

custom_query = """
default ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ scenario=oom-killed ë ˆì´ë¸”ì„ ê°€ì§„ íŒŒë“œë¥¼ ì°¾ì•„ì„œ
ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ìµœì ì˜ ë¦¬ì†ŒìŠ¤ ì„¤ì •ì„ ì¶”ì²œí•´ì¤˜.
"""

result = agent.agent.invoke({"input": custom_query})
print(result["output"])
```

## ì˜ˆì œ

### ê¸°ë³¸ ì˜ˆì œ ì‹¤í–‰

```bash
cd examples
python basic_usage.py
```

### ê³ ê¸‰ ì˜ˆì œ ì‹¤í–‰

```bash
python advanced_usage.py
```

## ì—ì´ì „íŠ¸ ì‘ë™ ë°©ì‹

1. **OOMKilled íŒŒë“œ ê°ì§€**
   - Kubernetes APIë¥¼ í†µí•´ OOMKilled ìƒíƒœì˜ íŒŒë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤
   - ì»¨í…Œì´ë„ˆ ìƒíƒœì™€ ì¬ì‹œì‘ íšŸìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤

2. **ì •ë³´ ìˆ˜ì§‘**
   - íŒŒë“œì˜ ë¦¬ì†ŒìŠ¤ ì„¤ì • (requests, limits)
   - Kubernetes ì´ë²¤íŠ¸ (OOMKilled ë°œìƒ ì‹œì )
   - ì»¨í…Œì´ë„ˆ ë¡œê·¸ (ë©”ëª¨ë¦¬ í• ë‹¹ íŒ¨í„´)

3. **AI ë¶„ì„**
   - GPT-4ê°€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„
   - ë©”ëª¨ë¦¬ ë¶€ì¡±ì˜ ì›ì¸ íŒŒì•… (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜, ìŠ¤íŒŒì´í¬ ë“±)
   - ì ì ˆí•œ ë©”ëª¨ë¦¬ ë¦¬ë¯¸íŠ¸ ê³„ì‚°

4. **í•´ê²°ì±… ì œì‹œ**
   - ì¶”ì²œ ë©”ëª¨ë¦¬ ë¦¬ë¯¸íŠ¸
   - Deployment ìˆ˜ì • ë°©ë²•
   - ì¶”ê°€ ìµœì í™” ì œì•ˆ

## í…ŒìŠ¤íŠ¸

OOM í…ŒìŠ¤íŠ¸ íŒŒë“œë¥¼ ë°°í¬í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# OOM í…ŒìŠ¤íŠ¸ íŒŒë“œ ë°°í¬
kubectl apply -f ../manifests/oom-test.yaml

# íŒŒë“œê°€ OOMKilled ë  ë•Œê¹Œì§€ ëŒ€ê¸°
kubectl get pods -w

# ì—ì´ì „íŠ¸ë¡œ ë¶„ì„
python main.py -n default -p oom-test
```

## LLM Provider ë¹„êµ

| íŠ¹ì§• | Gemini | OpenAI |
|------|--------|--------|
| **ê°€ê²©** | ë¬´ë£Œ í‹°ì–´ ì œê³µ (ì›” 60 ìš”ì²­/ë¶„) | ìœ ë£Œ (í† í°ë‹¹ ê³¼ê¸ˆ) |
| **ì„±ëŠ¥** | Gemini 1.5 Pro - ìš°ìˆ˜ | GPT-4 Turbo - ìµœê³  |
| **ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°** | 2M í† í° (ë§¤ìš° í¬ë‹¤!) | 128K í† í° |
| **í•œêµ­ì–´ ì§€ì›** | ìš°ìˆ˜ | ìš°ìˆ˜ |
| **ì¶”ì²œ ìš©ë„** | í…ŒìŠ¤íŠ¸, ê°œë°œ, ë¬´ë£Œ ì‚¬ìš© | í”„ë¡œë•ì…˜, ìµœê³  ì„±ëŠ¥ í•„ìš” ì‹œ |

**ê¶Œì¥ì‚¬í•­**: ê°œë°œ ë° í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œëŠ” Geminië¥¼ ì‚¬ìš©í•˜ê³ , í”„ë¡œë•ì…˜ ë°°í¬ ì‹œ ì„±ëŠ¥ì´ ì¤‘ìš”í•˜ë‹¤ë©´ OpenAIë¥¼ ê³ ë ¤í•˜ì„¸ìš”.

## ë„êµ¬ (Tools)

ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•˜ëŠ” Kubernetes ë„êµ¬ë“¤:

| ë„êµ¬ | ì„¤ëª… |
|------|------|
| `get_oomkilled_pods` | OOMKilled íŒŒë“œ ëª©ë¡ ì¡°íšŒ |
| `get_pod_details` | íŒŒë“œ ìƒì„¸ ì •ë³´ ì¡°íšŒ |
| `get_pod_logs` | ì»¨í…Œì´ë„ˆ ë¡œê·¸ ì¡°íšŒ |
| `get_pod_events` | Kubernetes ì´ë²¤íŠ¸ ì¡°íšŒ |
| `suggest_resource_update` | ë¦¬ì†ŒìŠ¤ ì—…ë°ì´íŠ¸ ê°€ì´ë“œ |

## í–¥í›„ Go ë§ˆì´ê·¸ë ˆì´ì…˜

ì´ í”„ë¡œì íŠ¸ëŠ” Pythonìœ¼ë¡œ í”„ë¡œí† íƒ€ì…ì„ ë§Œë“¤ê³ , ì¶”í›„ Goë¡œ í¬íŒ…í•  ì˜ˆì •ì…ë‹ˆë‹¤.

Go ë²„ì „ì—ì„œ ê³ ë ¤í•  ì‚¬í•­:
- `client-go` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
- Gemini/OpenAI API ì§ì ‘ í˜¸ì¶œ ë˜ëŠ” LangChain Go í¬íŠ¸ ì‚¬ìš©
- ì„±ëŠ¥ ìµœì í™” ë° ë™ì‹œì„± ì²˜ë¦¬
- ë°”ì´ë„ˆë¦¬ ë°°í¬ë¡œ ê°„í¸í•œ ì„¤ì¹˜

## ë¬¸ì œ í•´ê²°

### "No module named 'kubernetes'" ì—ëŸ¬
```bash
pip install -r requirements.txt
```

### Kubernetes ì—°ê²° ì—ëŸ¬
```bash
# kubeconfig í™•ì¸
echo $KUBECONFIG
kubectl cluster-info

# ë˜ëŠ” .envì—ì„œ KUBECONFIG ê²½ë¡œ ìˆ˜ì •
```

### Gemini API ì—ëŸ¬
```bash
# API í‚¤ í™•ì¸
cat .env | grep GEMINI_API_KEY

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
export GEMINI_API_KEY=your-key
```

### OpenAI API ì—ëŸ¬
```bash
# API í‚¤ í™•ì¸
cat .env | grep OPENAI_API_KEY

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
export OPENAI_API_KEY=sk-your-key
```

### Provider ë³€ê²½í•˜ê¸°
```bash
# .env íŒŒì¼ì—ì„œ LLM_PROVIDER ë³€ê²½
LLM_PROVIDER=gemini  # ë˜ëŠ” openai

# ë˜ëŠ” CLIì—ì„œ ì§ì ‘ ì§€ì •
python main.py -n default --provider gemini
```

## ë¼ì´ì„ ìŠ¤

MIT

## ê¸°ì—¬

ì´ìŠˆì™€ PRì„ í™˜ì˜í•©ë‹ˆë‹¤!
